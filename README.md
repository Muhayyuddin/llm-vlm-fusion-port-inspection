# LLM-VLM Fusion: Intelligent Maritime Autonomous Systems

## ğŸŒŠ Overview

The **LLM-VLM Fusion** project is an advanced autonomous maritime system that integrates Large Language Models (LLM) and Vision-Language Models (VLM) for intelligent control and coordination of heterogeneous USV-UAV operations. This system combines natural language understanding, computer vision, and autonomous navigation to enable sophisticated maritime missions including surveillance, inspection, and survey operations.

## ğŸš€ System Architecture

This project implements a comprehensive autonomous maritime platform featuring:

- **ğŸ¤– LLM-based Mission Planning**: Natural language mission interpretation and execution
- **ğŸ‘ï¸ VLM Integration**: Vision-language understanding for environmental awareness
- **ï¿½ Real-time Visual Inspection**: Florence, Quen2VL, SmolVLM-powered analysis
- **ï¿½ğŸš¢ USV Autonomous Navigation**: Advanced surface vessel control and guidance
- **ğŸš UAV Coordination**: Aerial vehicle integration for comprehensive coverage
- **ğŸ”— Heterogeneous Coordination**: Seamless USV-UAV collaborative operations

## ğŸ“ Project Structure

### ğŸ“‚ `nav2/` - USV SLAM & Navigation
**Purpose**: Advanced SLAM (Simultaneous Localization and Mapping) and autonomous navigation for USV operations.

**Key Features**:
- Real-time maritime SLAM implementation
- Obstacle avoidance and path planning
- Localization in GPS-denied environments
- Maritime-specific navigation algorithms
- Integration with ROS2 Navigation Stack (Nav2)

**Components**:
- SLAM algorithms for maritime environments
- Costmap generation and obstacle detection
- Path planning and trajectory optimization
- Localization and mapping modules

---

### ğŸ“‚ `nav_packages/` - USV Control & Guidance
**Purpose**: Low-level control systems and guidance algorithms for USV operations.

**Key Features**:
- PID-based motion control
- Dynamic positioning systems
- Thrust allocation and propulsion control
- Waypoint following and trajectory tracking
- Maritime dynamics modeling

**Components**:
- Controller implementations (PID, MPC)
- Guidance systems for maritime navigation
- Thrust vectoring and allocation
- State estimation and filtering
- Hardware abstraction layers

---

### ğŸ“‚ `uav_navigation/` - UAV Control & Guidance
**Purpose**: Comprehensive UAV control systems with advanced mission capabilities.

**Key Features**:
- 3D flight control and navigation
- Mission execution with waypoint management
- Circular inspection patterns
- Survey operations (rectangular/zigzag patterns)
- Landing operations including USV deck landing
- Obstacle avoidance and safety systems

**Components**:
- Flight control algorithms
- Mission executor with pattern generation
- Takeoff, landing, and hover capabilities
- Survey pattern algorithms (rectangular, zigzag)
- Circular inspection around targets
- Coordinated landing on moving USV platform

---

### ğŸ“‚ `vlm_inspection/` - Vision-Language Model Inspection
**Purpose**: Advanced visual inspection system using state-of-the-art Vision-Language Models for real-time analysis of camera feeds.

**Key Features**:
- **ğŸ” Multi-Model Integration**: Florence, Quen2VL, SmolVLM support
- **ğŸ“¸ Real-time Processing**: Live camera feed analysis
- **ğŸ§  Intelligent Detection**: Object recognition and anomaly detection
- **ğŸ“ Natural Language Descriptions**: Automated inspection reports
- **ğŸš¢ğŸš Dual Camera Support**: USV and UAV camera integration

**Components**:
- VLM model inference engines
- Camera topic subscribers (`/usv/slot0/image_raw`, `/quadrotor_1/slot0/image_raw`)
- Real-time image processing pipeline
- Inspection result publishers
- Model management and switching

---

### ğŸ“‚ `unified_mission_planner/` - LLM-based Mission Planning
**Purpose**: Intelligent mission planning system using Large Language Models for heterogeneous USV-UAV coordination.

**Key Features**:
- **ğŸ§  GPT-4 Integration**: Natural language mission interpretation
- **ğŸ“‹ Symbolic Mission Planning**: Mathematical action framework
- **ğŸ”— Dependency Management**: Coordinated execution with preconditions
- **ğŸš¢ğŸš Heterogeneous Coordination**: Seamless USV-UAV collaboration
- **ğŸ“Š Survey Operations**: Advanced area coverage algorithms
- **ğŸ” Inspection Missions**: Orbital and pattern-based inspections

**Mathematical Framework**:
```
Action Set = {Takeoff, FlyTo, Survey, Record, Hover, Navigate, Dock, LandOnUSV, Inspect, Report, GoHome}
Symbolic Action: Ï„áµ¢ = aáµ¢(robot, {Î¸áµ¢}, {Ïƒáµ¢})
Dependency Graph: P(Ï„â±¼) = P_spatial âˆª P_seq âˆª P_causal
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- **ROS2 Galactic** or newer
- **Python 3.8+**
- **OpenAI API key** (for LLM integration)
- **Ignition Gazebo** (for simulation)

### Build Instructions
```bash
# Navigate to workspace
cd /path/to/your/workspace

# Install dependencies
rosdep install --from-paths src --ignore-src -r -y

# Build the packages
colcon build --packages-select nav2 nav_packages uav_navigation unified_mission_planner vlm_inspection

# Source the workspace
source install/setup.bash
```

## ğŸš€ Quick Start

### 1. Launch Maritime Simulation
```bash
# Start the maritime simulation environment
ros2 launch mbzirc_ros competition_local.launch.py
```

### 2. Start USV Navigation System
```bash
# Launch USV SLAM and navigation
ros2 launch nav2 usv_navigation.launch.py

# Start USV control system
ros2 launch nav_packages usv_control_system.launch.py
```

### 3. Start UAV System
```bash
# Launch UAV mission executor
ros2 launch uav_navigation uav_mission_system.launch.py
```

### 4. Start Intelligent Mission Planner
```bash
# Launch LLM-based heterogeneous mission planner
ros2 launch unified_mission_planner heterogeneous_mission_system.launch.py
```

## ğŸ¯ Mission Capabilities

### Supported Mission Types

#### ğŸ” **Survey Operations**
- **Rectangular Survey**: Perimeter coverage for area inspection
- **Zigzag Survey**: Complete area coverage with optimal patterns
- **Adaptive Coverage**: LLM-optimized survey patterns

#### ğŸ” **Inspection Missions**
- **Circular Inspection**: Orbital patterns around targets
- **Multi-angle Inspection**: Comprehensive target analysis
- **Structure Assessment**: Maritime infrastructure evaluation

#### ğŸš¢ğŸš **Coordinated Operations**
- **Sequential Execution**: Dependency-based mission coordination
- **Parallel Operations**: Simultaneous USV-UAV tasks
- **Adaptive Coordination**: LLM-optimized collaboration

### Example Mission Commands
```python
# Survey Command
"survey_area": {
    "coordinates": [x1, y1, x2, y2],
    "altitude": 20.0,
    "method": "zigzag"  # or "rectangular"
}

# Inspection Command
"inspect_target": {
    "center": [x, y, z],
    "radius": 25.0,
    "pattern": "circular"
}

# Coordinated Landing
"land_on_usv": {
    "approach_altitude": 5.0,
    "landing_threshold": 1.0
}
```

## ğŸ”§ Configuration

### LLM Configuration
Edit `unified_mission_planner/config/openai_key.json`:
```json
{
    "key": "your-openai-api-key-here"
}
```

### Mission Prompts
Customize mission planning in `unified_mission_planner/config/heterogeneous_prompt.txt`

### Navigation Parameters
- USV parameters: `nav_packages/config/usv_navigation_params.yaml`
- UAV parameters: `uav_navigation/config/uav_mission_params.yaml`

## ğŸ“Š System Integration

### Communication Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Mission   â”‚â—„â”€â”€â–ºâ”‚   GPT-4 API     â”‚
â”‚    Planner      â”‚    â”‚   Integration   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USV Control   â”‚â—„â”€â”€â–ºâ”‚   UAV Control   â”‚â—„â”€â”€â–ºâ”‚  VLM Inspection â”‚
â”‚   & Navigation  â”‚    â”‚   & Navigation  â”‚    â”‚    Module      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚                      â”‚
          â–¼                       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USV Camera     â”‚    â”‚  UAV Camera     â”‚    â”‚ Florence, Quen2VLâ”‚
â”‚  /usv/slot0/    â”‚    â”‚ /quadrotor_1/   â”‚    â”‚   SmolVLM, etc  â”‚
â”‚   image_raw     â”‚    â”‚ slot0/image_raw â”‚    â”‚   VLM Models    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Topic Interface
- **Mission Commands**: `/uav_mission_command`, `/target_vessel_pose`
- **Status Feedback**: `/uav_mission_step_complete`, `/reach_subgoal`
- **Coordination**: `/unified_mission_plan`, `/mission_status`
- **Camera Feeds**: `/usv/slot0/image_raw`, `/quadrotor_1/slot0/image_raw`
- **VLM Analysis**: `/vlm_inspection_results`, `/vlm_detection_annotations`

## ğŸ§ª Testing & Validation

### Unit Tests
```bash
# Run navigation tests
colcon test --packages-select nav_packages

# Run mission planning tests
colcon test --packages-select unified_mission_planner
```

### Integration Tests
```bash
# Test heterogeneous coordination
ros2 run unified_mission_planner test_coordination.py

# Test survey patterns
ros2 run uav_navigation test_survey_patterns.py
```

## ğŸ“ˆ Performance Metrics

- **Mission Success Rate**: >95% completion rate
- **Navigation Accuracy**: <1m positioning error
- **Coordination Latency**: <100ms response time
- **Survey Coverage**: >98% area coverage efficiency

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **ROS2 Community** for the navigation framework
- **OpenAI** for GPT-4 integration capabilities
- **Ignition Gazebo** for simulation environment
- **Maritime Research Community** for domain expertise

## ğŸ“ Contact

For questions and support:
- **Email**: [your-email@domain.com]
- **Project Repository**: [GitHub Link]
- **Documentation**: [Wiki/Documentation Link]

---

**ğŸŒŠ Enabling intelligent autonomous maritime operations through LLM-VLM fusion ğŸšğŸš¢**
